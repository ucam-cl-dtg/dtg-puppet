#! /usr/bin/env python2.7
# Fabric doesn't support python3 so we are stuck with 2.7

"""
Deploy the latest puppet, security fixes or Ubuntu release to all puppies.
"""

import argparse
import datetime
from datetime import timedelta
from fabric.api import cd, env, execute, output, parallel, run, sudo, show, task
from fabric.exceptions import CommandTimeout
from git import Repo, RemoteProgress
from jinja2 import Environment, FileSystemLoader
import os
import os.path
import pickle
import random
import socket
from StringIO import StringIO
import sys
import threading
import tempfile

# paramiko is used for ssh transport, make sure its logs go somewhere. (stderr)
import logging
logging.getLogger('paramiko.transport').addHandler(logging.StreamHandler())
logging.getLogger('paramiko').addHandler(logging.StreamHandler())


DTG_DOM = '.dtg.cl.cam.ac.uk'

DOM0 = 'root@husky0' + DTG_DOM
REMOTE_PREFIX = 'lick'

PUPPET_BARE = '/etc/puppet-bare'

POOL_SIZE = 8

SHA_LENGTH = 9

# No spaces in release name.
# Version we should be running
TARGET_UBUNTU_RELEASE = 1604

# Any VM older than this needs an emergency OS update.
MINIMUM_UBUNTU_RELEASE = 1510

# If the version is older than this it is probably not Ubuntu.
# TODO(oc243) properly read lsb_release
NOT_UBUNTU = 1004

template = ""
tasks_template = ""
machines = []
lick_status = {}

orig_pid = os.getpid()

prev_sent_tasks = 0

DEFAULT_OUT_DIR = "/usr/groups/dtg/dtg-infra/www"
OUT_FILE = "lick-{}.html".format(datetime.datetime.now().isoformat("-"))
TASKS_FILE = "tasks-{}".format(OUT_FILE)

MESSAGE_BUFFER_SIZE = 2048 ** 2
# Setting values larger than net.core.wmem_max won't work so you may need to do something like
# sudo sysctl net.core.wmem_max=1048576
# to avoid error messages about message being too large

class Aggregator(threading.Thread):

    def __init__(self, socket_name):
        threading.Thread.__init__(self)
        self.daemon = True
        self.socket_name = socket_name

    def run(self):
        global machines
        UnixSock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)
        UnixSock.bind(self.socket_name)

        while True:
            data = UnixSock.recv(MESSAGE_BUFFER_SIZE)
            new_data = pickle.loads(data)
            if isinstance(new_data, Machine):
                new_mc = new_data
                machines = [x for x in machines if x.name != new_mc.name]
                lick_status["machines"] = machines
                machines.append(new_mc)
            else:
                lick_status["tasks"].append(new_data)
            update_status()


class Machine(object):

    def __init__(self, name, hostname, repo, is_vm, uuid=None):
        self.name = name
        self.hostname = hostname
        self.repo = repo
        self.is_vm = is_vm
        self.uuid = uuid

        self.actions = ["Waiting for update"]
        self.status = "active"
        self.stdout = []
        self.stderr = []


# This is where we need to push first as it is the canonical place for the
# source code to be
ORIGIN = [
    Machine('github', 'git@github.com',
            'ucam-cl-dtg/dtg-puppet.git', False),
    Machine('gitlab-repo', 'git@gitlab.developers.cam.ac.uk',
            'cst/dtg/infrastructure/dtg-puppet.git', False),
]

PHYSICAL_MACHINES = [
    Machine('nas04', 'nas04' + DTG_DOM, PUPPET_BARE, False),
#    Machine('entropy', 'entropy' + DTG_DOM, PUPPET_BARE, False),
    Machine('africa01', 'africa01' + DTG_DOM, PUPPET_BARE, False),
    Machine('deviceanalyzer-www', 'deviceanalyzer-www' + DTG_DOM, PUPPET_BARE, False),
]

UPDATE_BLACKLIST = ['weather', 'nas04']


class RemoteHandler(RemoteProgress):

    """
    Prints output from the pre-receive handler, stripping irrelevant bits.
    """

    def __init__(self, vm_name):
        super(RemoteHandler, self).__init__()
        self.vm = vm_name

    def line_dropped(self, line):
        if ("Warning: Permanently added" not in line) and (line.strip() !=
                                                           "remote:"):
            print "%s: %s" % (self.vm, line)
            self.vm.stderr.append(line)
            update_status()

    def update(self, op_code, cur_count, max_count=None, message=''):
        if len(message) > 0:
            self.vm.stderr.append(message)
            update_status()
            print message


def get_machine_by_name(name):
    x = [x for x in machines if x.hostname == name or x.name == name]
    # Names should be unique
    return x[0]


def get_hostnames_by_machines(machines):
    return [x.hostname for x in machines]


def update_status():
    global prev_sent_tasks
    if os.getpid() == orig_pid:
        # Dump to a file
        with open(OUT_PATH, "wb") as f:
            os.fchmod(f.fileno(), 0664)
            f.write(template.render(lick_status))
        with open(TASKS_PATH, "wb") as f:
            os.fchmod(f.fileno(), 0664)
            f.write(tasks_template.render(lick_status))
        prev_sent_tasks = len(lick_status["tasks"])
    else:
    # Send our state to the co-ordinator
        UnixSock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)
        UnixSock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, MESSAGE_BUFFER_SIZE)
        UnixSock.sendto(pickle.dumps(get_machine_by_name(env.host)),
                       socket_name)
        for i in range(prev_sent_tasks, len(lick_status["tasks"])):
            UnixSock.sendto(pickle.dumps(lick_status["tasks"][i]),
                           socket_name)
        prev_sent_tasks = len(lick_status["tasks"])


def machine_err(mc_name):
    mc = get_machine_by_name(mc_name)
    mc.status = "danger"


def machine_succ(mc_name):
    mc = get_machine_by_name(mc_name)
    if mc.status != "danger":
        mc.status = "success"


def update_progress(mc_name, stage):
    mc = get_machine_by_name(mc_name)
    mc.actions.append(stage)
    current_task("[%s] %s" % (mc_name, stage))


def current_task(task):
    lick_status["tasks"].append("[%s] %s" % (datetime.datetime.now(), task))
    update_status()


def ensure_dir(d):
    if not os.path.exists(d):
        os.makedirs(d)


def sudo_capture(cmd):
    stdout = StringIO()
    stderr = StringIO()
    result = sudo(cmd, stdout=stdout, stderr=stderr)
    machine = get_machine_by_name(env.host)
    for l in result.split('\n'):
        try:
            l = str(l).encode('ascii', errors='ignore')
        except UnicodeDecodeError:
            # Ignore any junk unicode printed. It's normally by
            # Ubuntu printing out loading dots.
            sys.stderr.write("%s\n" % l)
            continue
        if "[1;31m" in l:
            # Puppet's way of writing out errors.
            machine.stderr.append(l.strip())
        else:
            machine.stdout.append(l.strip())
    # stdout is handled above by result but standard error needs to be dealt with too
    stdout.close()
    err = stderr.getvalue()
    stderr.close()
    if len(err) > 0:
        for l in err.split('\n'):
            try:
                l = str(l).encode('ascii', errors='ignore')
            except UnicodeDecodeError:
                # Ignore any junk unicode printed. It's normally by
                # Ubuntu printing out loading dots.
                sys.stderr.write("%s\n" % l)
                continue
            else:
                machine.stderr.append(l.strip())
    if result.return_code:
        # Failed
        machine_err(machine.name)
    update_status()
    return result.return_code


@task
def get_os_versions():
    return run("lsb_release -rs | sed 's/\.//'", timeout=60)


def must_update(mc, version):
    return version < MINIMUM_UBUNTU_RELEASE and version >= NOT_UBUNTU


def should_update(mc, version):
    if version < NOT_UBUNTU:
        return False
    if version < MINIMUM_UBUNTU_RELEASE:
        return True
    if mc.name in UPDATE_BLACKLIST:
        return False
    if version < TARGET_UBUNTU_RELEASE:
        return True
    return False


@task
def get_vms():
    """
    Get a list of virtual machines on the husky servers.
    """
    uuids = run(
        'xe vm-list params=uuid power-state=running '
        'PV-bootloader=pygrub --minimal').split(',')
    names = run(
        'xe vm-list params=name-label power-state=running '
        'PV-bootloader=pygrub --minimal').split(',')
    vms = []
    for i, name in enumerate(names):
        # Look to see if we have a CNAME that is the same as the name in
        # XenCentaur
        hostname = "%s%s" % (name, DTG_DOM)
        if hostname == 'teaching-chime.dtg.cl.cam.ac.uk':
            continue
        try:
            socket.gethostbyname(hostname)
        except socket.error:
            # The VM doesn't have a proper CNAME. Sigh.
            # Reverse DNS its IP address to gets its puppy number.
            sys.stderr.write("%s does not have the CNAME %s%s\n" % (name, name,
                                                                    DTG_DOM))
            ip = run('xe vm-param-get param-name=networks uuid=%s | '
                     'sed -e \'s_0/ip: __\' -e  \'s/; .*$//\'' %
                     uuids[i])
            try:
                hostname = socket.gethostbyaddr(ip)[0]
            except socket.error:
                sys.stderr.write("Unable to lookup hostname of %s."
                                 "Check the VM has xe-guest-utilites installed\n"
                                 % name)
                continue
        vms.append(Machine(name, hostname, PUPPET_BARE, True, uuid=uuids[i]))

    # Randomize the order of vms. Otherwise we will starve the vms at the
    # end of the list if lick doesn't finish running
    random.shuffle(vms)
    return vms


def get_machines():
    """
    Get all remote hosts that need updating: git repos, VMs, and physical mcs.
    """
    vms = execute(get_vms, hosts=[DOM0])
    if not isinstance(vms, list) and not isinstance(vms, dict): # Error message rather than result
        raise vms
    machines = vms[DOM0] + PHYSICAL_MACHINES
    return machines


@task
def snapshot_mc(mc, commit_id):
    """
    Snapshot a VM using commit_id as a snapshot name.
    """
    assert mc.is_vm

    new_snap_name = commit_id[0:SHA_LENGTH]
    cur_snaps = run(
        'xe snapshot-list  snapshot-of=%s params=name-label --minimal' %
        mc.uuid).split(',')
    if new_snap_name in cur_snaps:
        print('%s already has a snapshot for commit %s. Not snapshotting again'
              % (mc.name, new_snap_name))
        update_progress(mc.name, "Snapshot already exists for VM")
    else:
        print 'Snapshotting %s' % mc.name
        update_progress(mc.name, "Snapshotting")

        if run('xe vm-snapshot uuid=%s new-name-label=%s' %
                (mc.uuid, new_snap_name)).return_code:
            update_progress(mc.name, "Error snapshotting")
            machine_err(mc.name)
        else:
            update_progress(mc.name, "Snapshotted")


def is_hex(val):
    """
    Determines if val is a hex-encoded string.
    """
    try:
        int(val, 16)
    except ValueError:
        return False
    return True


@task
def snap_gc():
    """
    Deletes old snapshots that were created by the lick script.

    Any lick snapshot that is older than 14 days is removed to save space,
    and keep the snapshot chain low to aid performance.
    """
    current_task("Cleaning up old snapshots")
    snap_uuids = run('xe snapshot-list params=uuid --minimal').split(',')
    snap_names = run('xe snapshot-list params=name-label --minimal').split(',')
    snap_times = run(
        'xe snapshot-list params=snapshot-time --minimal').split(',')
    snap_times = [datetime.datetime.strptime(x, '%Y%m%dT%H:%M:%SZ') for x in
                  snap_times]
    keys = ('uuid', 'name', 'time')
    snaps = ([dict(zip(keys, data)) for data in
              zip(snap_uuids, snap_names, snap_times)])

   # filter out those snapshots where the timestamp field is > 14 days old
    snaps = [x for x in snaps if x['time'] < datetime.datetime.today()
             - timedelta(days=2)]

    # filter out snapshots whose name is not $SHA_LENGTH digits of hex
    snaps = [x for x in snaps if is_hex(x['name']) and
             len(x['name']) == SHA_LENGTH]

    if snaps:
        print 'Destroying %d old snapshots' % len(snaps)

    for snap in snaps:
        run('xe snapshot-uninstall force=true uuid=%s' % snap['uuid'])


@parallel(pool_size=POOL_SIZE)
def upgrade_mc():
    """
    Upgrade the base version of Ubuntu to the latest release.
    """
    # Remove unusued packages to reduce the chance of falling over
    # during the upgrade
    current_task("Upgrading OS version of %s" % env.host)
    with show('output'):
        update_progress(env.host, "Cleaning up before OS upgrade")
        # Disable fancy progress bars during the update, as they break fabric.
        sudo_capture('rm /etc/apt/apt.conf.d/99progressbar || true')
        # Remove any out of date packages before trying to upgrade.
        sudo_capture("apt-show-versions | grep :amd64 | grep -v uptodate |"
                     " grep -v xe-guest-utilities | sed 's/:.*$//' |"
                     ' xargs sudo apt-get -y -q remove')
        # Ensure the current version is up to date, as there may be a new
        # version of the updater.
        update_progress(env.host, "Refreshing apt indexes before OS upgrade")
        sudo_capture('apt-get update -q')
        update_progress(env.host,
                        "Upgrading current packages before OS upgrade")
        sudo_capture('apt-get -y -q --no-install-recommends dist-upgrade')
        # Try to get free space on the disk.
        update_progress(env.host, "Removing old packages before OS upgrade")
        # Remove linux-image-extra-* to get more space in /boot
        sudo_capture('apt-get -y -q remove linux-image-extra*')
        sudo_capture('apt-get -y -q autoremove')
        sudo_capture('rm -rf /etc/apt/sources.list.d/*.{save,distUpgrade}')
        with cd('/etc/apt/sources.list.d/'):
            sudo_capture(
                'find . ! -name main.list ! -name security.list ! -name updates.list -delete')
        # Ensure do-release-upgrade doesn't just want to use LTS versions.
        sudo_capture("sed -i 's/Prompt=lts/Prompt=normal/' "
                     "/etc/update-manager/release-upgrades")
        # Desperately try to do a non-interactive upgrade.
        update_progress(env.host, "Removing stunnel before OS upgrade")
        sudo_capture('apt-get -q -y purge stunnel4')
        sudo_capture('rm -rf /etc/stunnel')
        sudo_capture(
            'echo \'DPkg::options { "--force-confdef"; "--force-confnew"; }\' > /etc/apt/apt.conf.d/90-dtg-upgrade')
        update_progress(env.host, "Attempting OS upgrade")
        if sudo_capture(
                'yes | '
                'DEBIAN_FRONTEND=noninteractive '
                'do-release-upgrade -f DistUpgradeViewNonInteractive'):
            #Upgrade failed
            update_progress(env.host, "Upgrade failed!")
            return
        update_progress(env.host, "OS upgrade successful")
        update_progress(env.host, "Cleaning up after OS upgrade")
        sudo_capture('rm -rf /etc/apt/apt.conf.d/90-dtg-upgrade')
        sudo_capture('rm /etc/apt/apt.conf.d/50unattended-upgrades.ucf-dist || true')
        # Remove any out of date packages after upgrading.
        sudo_capture("apt-show-versions | grep :amd64 | grep -v uptodate | "
                     "sed 's/:.*$//' |"
                     ' xargs sudo apt-get -y -q remove')
        # Clean up apt.
        sudo_capture('apt-get -q clean')
        sudo_capture('apt-get -q autoclean')
        sudo_capture('reboot')
        machine_succ(env.host)


@parallel(pool_size=POOL_SIZE)
def security_update():
    """
    Force machines to apply the latest security update.

    For when waiting for unattended upgrades is too risky.
    """
    update_progress(env.host, "Applying security updates")

    sudo_capture('apt-get -q update')
    sudo_capture('unattended-upgrade')
    sudo_capture('nice apt-get -y -q --no-install-recommends dist-upgrade')
    sudo_capture('nice apt-get -y -q autoremove')
    sudo_capture('nice apt-get -q clean')
    sudo_capture('nice apt-get -q autoclean')
    update_progress(env.host, "Security updates applied")
    machine_succ(env.host)


@parallel(pool_size=POOL_SIZE)
def run_latest_puppet(repourl, refspec):
    """
    Manually apply puppet.
    """
    update_progress(env.host, "Applying puppet")
    with show('output'):
        with cd(PUPPET_BARE):
            rc = sudo_capture('git fetch --quiet %s %s' % (repourl,
                                                           refspec))
            if rc:
                update_progress(env.host, "Error fetching latest puppet. "
                                "Running old verison.")
                machine_err(env.host)
            rc = sudo_capture('nice ./hooks/post-update')
            if rc:
                machine_err(env.host)
                update_progress(env.host, "Error running puppet.")
            else:
                update_progress(env.host, "Applied puppet")
                machine_succ(env.host)


def add_remotes(repo, machines):
    """
    Delete all remotes, then add those listed in `machines'
    """
    for remote in repo.remotes:
        if remote.name.startswith(REMOTE_PREFIX):
            repo.delete_remote(remote)
    for mc in machines:
        repo.create_remote(REMOTE_PREFIX + '_' + mc.name,
                           mc.hostname + ':' + mc.repo)


def snapshot_machines(machines, commit_id):
    for mc in machines:
        if mc.is_vm:
            execute(snapshot_mc, mc, commit_id, hosts=[DOM0])


def update_machines(machines, friendly_upgrade):
    current_task("Finding machines that should have an OS update.")
    upgrade_mcs = []
    for mc in machines:
        version = ''
        try:
            version = execute(get_os_versions, hosts=[mc.hostname])
        except CommandTimeout:
            update_progress(mc.name, "Timed out getting OS version")
            machine_err(mc.name)
            continue
        try:
            version = int(version[mc.hostname])
        except TypeError:
            sys.stderr.write("Unable to get OS version for %s\n" % mc.name)
            continue
        mc.os = version
        # Some machines must be updated even if we're not using the
        # do-release-upgrade flag as they are insecure.
        if must_update(mc, version):
            upgrade_mcs.append(mc.hostname)
            # Others we want to friendly update.
        elif friendly_upgrade:
            if should_update(mc, version):
                upgrade_mcs.append(mc.hostname)
        update_status()
    if upgrade_mcs:
        current_task("Going to upgrade Ubuntu on: " + ", ".join(upgrade_mcs))
        execute(upgrade_mc, hosts=upgrade_mcs)
        current_task("Finished upgrading Ubuntu")


def push_to_repos(repo, machines):
    """
    Push the current version of puppet to the various repos.

    Args:
        repo: local git repository containing python.
        machines: machines to apply the updates to.
    """
    hostnames = get_hostnames_by_machines(machines)

    for mc in ORIGIN:
        current_task("Pushing puppet to %s" % mc.name)
        handler = RemoteHandler(mc.name)
        remote = repo.remotes[REMOTE_PREFIX + '_' + mc.name]
        info = remote.push(refspec='master:master', progress=handler)[0]
        if not (info.flags & (info.NEW_TAG | info.NEW_HEAD | info.UP_TO_DATE |
                              info.FAST_FORWARD)):
            sys.stderr.write(info.summary)
            sys.stderr.write("Incorrect flag whilst pushing to %s: %d. "
                             "Terminating.\n" % (mc.name, info.flags))
            sys.exit(-1)


def main(args, socket_name):
    """
    Update DTG machines.
    """
    output['running'] = False
    output['stdout'] = False

    Aggregator(socket_name).start()
    ensure_dir(OUT_DIR)
    try:
        os.unlink("%s/lick-latest.html" % OUT_DIR)
    except OSError:
        # Symlink doesn't exist. Who cares?
        pass
    os.symlink(OUT_FILE, "%s/lick-latest.html" % OUT_DIR)

    jinja_env = Environment(loader=FileSystemLoader(os.path.dirname(
        os.path.realpath(__file__))),
        trim_blocks=True)
    global template
    global tasks_template
    template = jinja_env.get_template('deploy-status.html')
    tasks_template = jinja_env.get_template('tasks-status.html')
    lick_status["deploy_time"] = datetime.datetime.now()
    lick_status["licker"] = os.getenv("USER")
    lick_status["version"] = ""
    lick_status["tasks"] = []
    lick_status["machines"] = []
    lick_status["tasks_url"] = TASKS_URL

    current_task("Lick initiatisation")
    update_status()

    env.warn_only = True
    env.skip_bad_hosts = True
    env.keepalive = 1
    env.connection_attempts = 3
    env.disable_known_hosts = True

    repo = Repo('.', search_parent_directories=True)
    lick_status["version"] = repo.head.commit.hexsha
    global machines
    machines = []

    add_remotes(repo, ORIGIN + machines)

    # Does args.machines contain hostnames? If so, let's use those
    # and avoid talking to dom0 (so dom0 is needed)
    if args.machines:
        # If only one machine is specified then we need it to be a
        # one element list.
        if isinstance(args.machines, str):
            args.machines = [args.machines]
        for mc in args.machines:
            try:
                socket.gethostbyname(mc)
                machines.append(Machine(name=mc.split(".")[0],
                                        hostname=mc,
                                        repo="/etc/puppet-bare",
                                        is_vm=False))

            except socket.error:
                # One of the arguments was not a valid hostname.
                # Let's consult dom0 to work out what's going on.
                # Get rid of the machines we've found by hostname
                # and abort hostname checks.
                machines = []
                break

    # We haven't received a list of hostnames. Use dom0 to get VM
    # names.
    if not machines:
        machines = get_machines()
        if args.machines:
            machines = [x for x in machines if x.name in args.machines]
    # A bad filter was applied so we can't lick any machines.
    if not machines:
        sys.stderr.write("No machines to apply puppet to")
        sys.exit(-1)
    lick_status["machines"] = machines
    update_status()
    print("Streaming status to %s" % OUT_URL)
    hostnames = get_hostnames_by_machines(machines)

    # Remove old lick-generated snapshots, or else they build up
    if not args.no_snap_gc:
        execute(snap_gc, hosts=[DOM0])

    if not args.no_snap:
        snapshot_machines(machines, repo.head.commit.hexsha)
    if not args.no_update:
        update_machines(machines, args.upgrade)
    if args.security_update:
        execute(security_update, hosts=hostnames)
    if not args.no_push:
        push_to_repos(repo, machines)

    execute(run_latest_puppet, args.repourl, args.refspec,
            hosts=hostnames)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Pushes the master branch of dtg-puppet, as found on '
        'github all over the world')
    parser.add_argument('--do-release-upgrade', action='store_true',
                        dest='upgrade',
                        help='Upgrade the version of Ubuntu before '
                        'applying the puppet config')
    parser.add_argument('--no-snap-gc', action='store_true',
                        dest='no_snap_gc', help='Do not remove old snapshots')
    parser.add_argument('--security-update', action='store_true',
                        dest='security_update',
                        help='Apply all security updates immediately')
    parser.add_argument('--repourl', help='URL of the git repository '
                        'containing puppet that should be applied.',
                        default='https://github.com/ucam-cl-dtg/dtg-puppet.git')
    parser.add_argument('--refspec', help='refspec that should be '
                        'pulled from. Caution, if this doesn\'t get '
                        'merged into master life gets difficult.',
                        default='master:master')
    parser.add_argument('--no-root', dest='no_root', action='store_true',
                        help='Don\'t do anything which requires root on DOM0 '
                             'or admin on the infrastructure repository. '
                             'Implies --no-snap --no-snap-gc --no-push.')
    parser.add_argument('--no-snap', dest='no_snap',
                        help='Don\'t snapshot machines.',
                        action='store_true')
    parser.add_argument('--no-update', dest='no_update',
                        help='Don\'t attempt to update machines.',
                        action='store_true')
    parser.add_argument('--no-push', dest='no_push',
                        help='Don\'t push the current config to our '
                        'code repositories.',
                        action='store_true')
    parser.add_argument('--out-dir', dest='out_dir',
                        help='Directory to write the lick status to.',
                        default=DEFAULT_OUT_DIR)
    parser.add_argument('machines', nargs='*',
                        help='Limit the machines that the lick is applied to')

    args = parser.parse_args()

    if args.no_root:
        args.no_snap = True
        args.no_snap_gc = True
        args.no_push = True

    # Set "constants" based on arguments:

    OUT_PATH = "%s/%s" % (args.out_dir, OUT_FILE)
    OUT_URL = "https://www.cl.cam.ac.uk/research/dtg/infra/%s" % OUT_FILE
    TASKS_PATH = "%s/%s" % (args.out_dir, TASKS_FILE)
    TASKS_URL = "https://www.cl.cam.ac.uk/research/dtg/infra/%s" % TASKS_FILE
    OUT_DIR = args.out_dir

    tempdirname = tempfile.mkdtemp()
    socket_name = os.path.join(tempdirname, 'deploy_unix_socket')
    try:
        main(args, socket_name)
    finally:
        os.remove(socket_name)
        os.rmdir(tempdirname)
